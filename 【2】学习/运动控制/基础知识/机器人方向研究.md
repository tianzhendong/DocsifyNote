# 机器人方向研究

[toc]

## 机器人科普



## 工业机器人控制器

文章[工业机器人控制器](https://blog.csdn.net/robinvista/article/details/88085020)做了详细的调研

## 运动规划、运动控制 & 运动感知

参考[文章](https://www.guyuehome.com/34932)

![img](https://gitee.com/tianzhendong/img/raw/master//images/202202241428372.jpeg)

大致可以分为三个模块：运动规划、运动控制和运动感知

### 运动规划

按照高飞老师的《运动规划》课程的介绍，运动规划（Motion Planning）指的是两部分：前端路径规划（Path Finding，Path Planning，这些名词都差不多）与后端轨迹优化（Trajectory Optimization，Trajectory Generation，这些名词也都差不多）

#### 路径规划

- 根据所得到的感知信息和预设目标位置，规划一条机器人从初始位置到目标位置的路径
- 只考虑工作空间的几何约束，不考虑机器人的运动学模型和约束

**路径规划算法**有三类：

1. 基于搜索的算法：有Dijkstra算法、A*算法、JPS算法等
2. 基于采样的算法：RRT算法、PRM算法等
3. 动力学约束算法：State Lattice Search、Kinodynamic RRT*算法、Hybrid A*算法等

#### 轨迹优化

- 给定路径与机器人约束，生成一组控制序列，使得机器人从初始位姿移动到目标位姿
- 考虑机器人的运动学模型和约束

1. 轨迹优化其实是对路径的优化，为路径赋予时间尺度
2. 高维、连续空间

**轨迹优化算法**通常将问题转化为一个最优控制理论，求解优化问题的算法通常有：

1. 解析法：变分法、极大值原理、动态规划等
2. 数值法：直接配置法
3. 动力学算法：MPC等

从变分法可以延伸出来的通用轨迹规划算法（拟合），通过直接配置法得到的多段轨迹规划算法（插值），从简化动力学得到的MPC算法，这都是后面需要整理的



### 运动控制

运动控制（Motion Control）是由双环控制系统组成（可能不是很准确，希望能跟大家交流讨论）：外环设计控制策略（Control Strategy），内环设计控制模型（Control Model）

#### 控制策略

- 基于任务的类型，可以把控制策略划分为：自由空间的位置控制与接触空间的力控制（更广泛地说：柔顺控制）策略
- 通常控制策略是基于任务空间（操作空间，笛卡尔空间，或者说不是关节空间）

**控制策略**的分类：

1. 位置控制策略：这个其实和轨迹优化有重叠的部分，此外，还可以在任务空间做“位置闭环”
2. 柔顺控制策略：柔顺控制分为被动柔顺（机械装置）和主动柔顺控制（力控制），最简单的是刚度控制、阻尼控制等这种纯力控制
3. 组合控制策略：大家比较熟悉的力/位置混合控制、阻抗控制

其实更一般化地控制策略是：**混合阻抗控制**，融合了力位混合控制和阻抗控制的优点，将任务空间划分为位控子空间和力控子空间，然后分别在两个子空间进行阻抗设计

#### 控制模型

> 对外环的控制策略进行跟踪控制

看起来挺简单的，这么说直接用开环控制即可，但是开环控制通常不好使，因为有误差，所以引入了感知系统做闭环控制（或者说是反馈控制）；单纯的反馈控制也不行啊，因为得知道你控制的是个啥吧，所以得对系统建模；还得知道外界的干扰也是个啥，所以得对扰动观测。

于是乎又存在三个问题：观测误差（来源于传感器噪声，微分噪声等）、建模误差（来源于未建模动态、模型不准等）和扰动误差（来源于外界干扰）

所以控制模型主要研究以下问题

- **控制模型**的分类：

1. 无模型控制还是基于模型控制算法：典型的代表分别是PID算法和计算力矩法
2. 解决建模误差的算法：系统辨识、自适应控制算法等
3. 解决扰动误差的算法：鲁棒控制、ADRC为代表的扰动观测器算法等
4. 解决观测误差的算法：以Kalman滤波器为代表的状态估计（这其实和运动感知有重叠的部分）



### 运动感知

运动感知（Motion Perception）主要也是包括两个部分：感知系统（Perception System）和观测器（Observer）

#### 感知系统

> 对自身状态和与外界交互状态进行测量的装置或系统

- 内感系统：编码器、IMU等
- 外感系统：激光、雷达、相机、GPS等

需要注意的是：我们不专门去研究它的工艺，至少需要了解如何去使用，或者说调库

#### 状态估计

- 运动规划需要状态估计：做建图，定位、导航等
- 运动控制需要状态估计：信号滤波啊，机器人位置、速度等的估计

需要注意的是：这里面一方面是状态估计的算法，另外一方面是多传感器信息如何进行融合（融合：贝叶斯告诉我们，两个臭皮匠（两个不精确的传感器）顶个诸葛亮（一个不精确的传感器））

状态估计的算法

1. Luenberger观测器为代表的观测器模型
2. Naïve Kalman滤波、EKF、UKF等
3. 融合算法

## 机器视觉-目标识别



参考[从机器人视觉识别领域-三维目标识别方向讲起](https://www.guyuehome.com/34795)

目前在机器人实时抓取策略算法主要存在两种大的分类，一种是以Linemod算法为代表的**传统的图像处理算法**，另一种则是最近几年开展研究的**机器学习的方法**。而这两大分类包含了目前主流的四种方法：

###  基于点对特征

 2010年Bertram Drost等人提出了基于Point Pair 特征的**PPF(PointPairFeature)算法**。PPF算法使用物体的全局模型描述，基于定向点对特征，通过快速投票方案在本地匹配全局模型实现物体三维到二维搜索空间上的对应匹配识别，适用于快速监测点云较为稀疏或者缺乏表面纹理信息及局部曲率变化极小的物体。PPF算法在有噪声、部分遮挡情况下有较好的识别能力，然而其不能解决具有相似噪声背景下物体识别问题，而且并没有很好的利用物体的边缘信息。

### 基于模板匹配

 2011年Stefan Hinterstoisser等人提出针对3D刚性物体的实时检测与定位算法**LineMod算法**。其基本原理是通过提取物体各个方向的深度图像采集模型，采用彩色图像的梯度信息结合物体表面的法向特征作为模板匹配的依据，训练其方向梯度生成物体模板后与实际图像的各对应方向位置匹配推测匹配结果。

 最后利用ICP算法对检测结果进行位姿修正完成3D刚性物体的位置检测判断。虽然LineMod利用了物体的多种特征，很好的解决了多种类目标在简单场景下的物体识别，然而其在模板分类时只关注物体的边缘，导致其在稍复杂实时模板匹配时识别率大幅度下降。

2018年Tomas Hodan使用现有的数据集提出**BOP算法**，建立了新的模板分类基准。

然而其只能识别单个场景下多类物体的识别，遇到同类物体较多以及重叠场景算法识别能力迅速下降。

### 基于霍夫森林

 2009年Juergen Gall等人提出了基于**霍夫森林的目标检测算法**，通过构建一个随机森林（random forest）从图像上提取图像块，在构建的随机森林中的每个决策树上进行判断处理并在霍夫空间中进行投票，图像密集块采样后输出霍夫图像完成对目标重心位置的投票。

 当然在该算法提出后基于**Hough Forest算法**的目标检测也有着深入的发展。

###  基于深度学习

 2017年Wadim Kehl等人提出了基于**SSD算法**的三维物体6D位姿估计，通过将2D图像深度学习的思路与三维物体RGBD图像的特点，利用深度学习网络完成局部图像2D检测、特征图与预训练核卷积，并使用投影属性来解析深度网络推断的试点及平面内旋转分数以此构建6D位姿假设。

![image-20220224144501637](https://gitee.com/tianzhendong/img/raw/master//images/202202241445128.png)

目前深度相机主要的方法有：

1.基于霍夫变换

（可以参考2010年的论文 ppf (point pair feature)：Model Globally, Match Locally: Efficient and Robust 3D Object Recognition）

2.基于模板匹配（linemod算法）比1效果要更好

论文：Multimodal Templates for Real-Time Detection of Texture-less Objects in Heavily Cluttered Scenes

（http://campar.in.tum.de/pub/hinterstoisser2011linemod/hinterstoisser2011linemod.pdf）

3.基于patch匹配+random forest（Latent-Class Hough Forests 用于处理linemd在遮挡时候识别率下降的问题）

论文：Learning 6D Object Pose Estimation using 3D Object Coordinates

LCHF：https://arxiv.org/abs/1706.03285

4.基于点云

http://wiki.ros.org/pcl_ros/Tutorials

https://blog.csdn.net/shine_cherise/article/details/79285162（学习资料）

http://ros-developer.com/2017/05/15/object-recognition-and-6dof-pose-estimation-with-pcl-pointcloud-and-ros/（核心项目参考）（也就是https://github.com/adityag6994/3D_Object_Seg_CNN以及可以参考他的分享https://github.com/adityag6994/object_tracking_particle_filter）

https://blog.csdn.net/AmbitiousRuralDog/article/details/80268920（地面点云分割）

5.基于CNN end-to-end

论文：SSD-6D: Making RGB-based 3D detection and 6D pose estimation great agai